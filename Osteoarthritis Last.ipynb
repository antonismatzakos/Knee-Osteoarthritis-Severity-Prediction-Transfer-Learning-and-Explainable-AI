{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install tensorflow\n#!pip install keras\n#!pip install --upgrade tensorflow\n#!pip install --upgrade tensorflow-gpu","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow\nfrom tensorflow import keras\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n#from tensorflow.keras.layers.normalization import BatchNormalization\nfrom tensorflow.keras.datasets import *\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Dense, Flatten,Dropout, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nimport itertools\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot as plt\nfrom tensorflow.keras.models import Model\nfrom datetime import datetime\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport os\nfrom sklearn.utils import class_weight\nimport tensorflow_addons as tfa\nimport pathlib\nfrom tensorflow.keras import regularizers\n#model = tensorflow.keras.models.load_model(\"../input/models/inception_val69167.h5\")\n#os.mkdir(\"/kaggle/working/models\")\nos.chdir(\"/kaggle/input/knee-osteoarthritis-dataset-with-severity\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_dir = \"/kaggle/input/knee-osteoarthritis-dataset-with-severity\"\ntrain_path = os.path.join(base_dir,'train')\nvalid_path = os.path.join(base_dir,'val')\ntest_path = os.path.join(base_dir, 'test')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport random\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom collections import Counter\nimport cv2\n\nig, ax = plt.subplots(5,5, figsize=(18,18))\n\nfor class_id in range(5):\n    folder = os.path.join(train_path,str(class_id))\n    os.chdir(folder)\n    samples = random.sample(os.listdir(folder), 5)\n    \n    for col in range(5):\n        image = cv2.imread(samples[col])\n        ax[class_id, col].imshow(image)\n        ax[class_id, col].set_title(\"class_\" + str(class_id))\n        ax[class_id, col].set_axis_off()\n    \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def random_erasing(img, sl=0.1, sh=0.2, rl=0.4, p=0.4):\n    h = tensorflow.shape(img)[0]\n    w = tensorflow.shape(img)[1]\n    c = tensorflow.shape(img)[2]\n    origin_area = tensorflow.cast(h*w, tensorflow.float32)\n\n    e_size_l = tensorflow.cast(tensorflow.round(tensorflow.sqrt(origin_area * sl * rl)), tensorflow.int32)\n    e_size_h = tensorflow.cast(tensorflow.round(tensorflow.sqrt(origin_area * sh / rl)), tensorflow.int32)\n\n    e_height_h = tensorflow.minimum(e_size_h, h)\n    e_width_h = tensorflow.minimum(e_size_h, w)\n\n    erase_height = tensorflow.random.uniform(shape=[], minval=e_size_l, maxval=e_height_h, dtype=tensorflow.int32)\n    erase_width = tensorflow.random.uniform(shape=[], minval=e_size_l, maxval=e_width_h, dtype=tensorflow.int32)\n\n    erase_area = tensorflow.zeros(shape=[erase_height, erase_width, c])\n    erase_area = tensorflow.cast(erase_area, tensorflow.uint8)\n\n    pad_h = h - erase_height\n    pad_top = tensorflow.random.uniform(shape=[], minval=0, maxval=pad_h, dtype=tensorflow.int32)\n    pad_bottom = pad_h - pad_top\n\n    pad_w = w - erase_width\n    pad_left = tensorflow.random.uniform(shape=[], minval=0, maxval=pad_w, dtype=tensorflow.int32)\n    pad_right = pad_w - pad_left\n\n    erase_mask = tensorflow.pad([erase_area], [[0,0],[pad_top, pad_bottom], [pad_left, pad_right], [0,0]], constant_values=1)\n    erase_mask = tensorflow.squeeze(erase_mask, axis=0)\n    erased_img = tensorflow.multiply(tensorflow.cast(img,tensorflow.float32), tensorflow.cast(erase_mask, tensorflow.float32))\n\n    return tensorflow.cond(tensorflow.random.uniform([], 0, 1) > p, lambda: tensorflow.cast(img, img.dtype), lambda:  tensorflow.cast(erased_img, img.dtype))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use GPU\nsess = tensorflow.compat.v1.Session(config=tensorflow.compat.v1.ConfigProto(log_device_placement=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base = tensorflow.keras.applications.DenseNet201(\n        include_top=False,\n        input_tensor=None,\n        input_shape=None)\nbase.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nlr = tensorflow.keras.callbacks.ReduceLROnPlateau(\n    monitor=\"val_loss\",\n    factor=0.1,\n    patience=9,\n    verbose=2,\n    mode=\"max\",\n    min_delta=0.0001,\n    min_lr=0.000001\n)\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    x = base.output\n    x= keras.layers.GlobalAveragePooling2D()(x)\n    x = keras.layers.Dropout(0.4)(x)\n    predictions =Dense(units=5, activation = 'softmax', kernel_regularizer=regularizers.l1_l2(l1=0.02, l2=0.02))(x)\n    model = Model(inputs=base.input, outputs=predictions)\n    model.compile(Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n    model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch=32\ntrain_batches= ImageDataGenerator(horizontal_flip=True,\n    vertical_flip=True,\n    shear_range=0.3,rotation_range=40,\n    width_shift_range=0.25,\n    height_shift_range=0.15,\n    zoom_range=0.2,\n    preprocessing_function = random_erasing).flow_from_directory(train_path, target_size=(224,224), classes=['0','1','2','3','4'], batch_size=batch)\nvalid_batches= ImageDataGenerator().flow_from_directory(valid_path, target_size=(224,224), classes=['0','1','2','3','4'], batch_size=batch)\ntest_batches= ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224), classes=['0','1','2','3','4'], batch_size=batch, shuffle= False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n class_weights = class_weight.compute_class_weight(\n            'balanced',\n             np.unique(train_batches.classes), \n             train_batches.classes)\n\n train_weights = dict(enumerate(class_weights))\n train_weights\n '''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint(filepath='/kaggle/working/Best_DenseNet201.h5',verbose=2, save_best_only=True, monitor = 'val_accuracy')\n\ne = tensorflow.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=20, verbose=2, restore_best_weights=True)\n\ncallbacks = [checkpoint, e]\n\nstart = datetime.now()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_batches, steps_per_epoch=5778//batch, validation_data=valid_batches, validation_steps=826//batch, epochs=120, verbose=2, callbacks = callbacks)\n\nduration = datetime.now() - start\nprint(\"Training completed in time: \", duration)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.save('/kaggle/working/densenet.h5')\n#model = keras.models.load_model('/kaggle/working/Best_dense2.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(test_batches)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training & validation accuracy values\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix and Classification Report\nY_pred = model.predict_generator(test_batches, 1656 // 32+1)\ny_pred = np.argmax(Y_pred, axis=1)\nprint('Confusion Matrix')\nprint(confusion_matrix(test_batches.classes, y_pred))\nprint('Classification Report')\ntarget_names = ['0','1','2','3','4']\nprint(classification_report(test_batches.classes, y_pred, target_names=target_names))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}